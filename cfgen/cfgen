#!/usr/bin/env python3

import abc
import argparse
import ast
from enum import Enum, auto
from glob import glob
import json
import os
from pprint import pprint
import random
import re
import subprocess
import socket
import sys
from typing import Any, Callable, Dict, Iterator, List, NamedTuple, Set, \
    Tuple, Union
import yaml


__version__ = '0.2'
__author__ = 'Valery V. Vorotyntsev <valery.vorotyntsev@seagate.com>'


def parse_opts(argv):
    p = argparse.ArgumentParser(
        description='Generate configuration files required to start'
        ' Mero cluster.',
        usage='%(prog)s [-o <output-dir>] [--mock]',
        epilog='The program reads cluster description in YAML format from the'
        " standard input; '--help-schema' option shows the schema.")
    p.add_argument('--help-schema', nargs=0, help='show cluster description'
                   ' file schema', action=ShowSchema)
    default_dhall_dir = '/opt/cfgen/dhall'
    p.add_argument('-D', '--dhall', metavar='dir',
                   help='directory with auxiliary Dhall expressions'
                   f' (defaults to {default_dhall_dir!r})',
                   dest='dhall_dir', default=default_dhall_dir)
    p.add_argument('-o', metavar='output-dir',
                   help="output directory (defaults to '.')",
                   dest='output_dir', default='.')
    p.add_argument('--mock', help='Generate pseudo-random "facts". The hosts'
                   ' specified in the cluster description file will not be'
                   " visited and don't even have to exist.",
                   action='store_true')
    p.add_argument('--debug',
                   help='print the enriched cluster description and exit',
                   action='store_true')
    p.add_argument('-V', '--version', action='version',
                   version='%(prog)s ' + __version__)
    opts = p.parse_args(argv)

    # Sanity check.
    for opt, d, perm in [('--dhall', opts.dhall_dir, os.R_OK),
                         ('-o', opts.output_dir, os.W_OK)]:
        if not (d and os.path.isdir(d) and os.access(d, os.X_OK | perm)):
            what = 'read' if perm == os.R_OK else 'writ'
            die(f'{opt!r} argument must be a path to {what}able directory')

    opts.dhall_dir = os.path.abspath(opts.dhall_dir)
    return opts


class ShowSchema(argparse.Action):
    def __call__(self, *args):
        print("""\
# Cluster Description is a YAML file with the following schema:
---  # start of the document (optional)
hosts:
  - name: <str>  # [user@]hostname; e.g., localhost, samir@10.22.33.44
    disks:
    m0_servers:
      - runs_confd: <bool>  # optional, defaults to false
        #io_disks: null                 # no IO service
        io_disks: { path_glob: <str> }  # e.g. "/dev/loop[0-9]*"
    c0_clients: <int>        # max quantity of Clovis apps this host may have
    m0t1fs_clients: <int>    # max quantity of m0t1fs clients
pools:
  - name: <str>
    allowed_failures:  # optional section; no failures will be allowed
                       # if this section is missing or all of its elements
                       # are zeroes
      site: <int>
      rack: <int>
      encl: <int>
      ctrl: <int>
      disk: <int>
    data_units: <int>
    parity_units: <int>
    #
    # There are two ways of assigning disks to pool.
    #
    # 1) Choose which disks of which host to use for this pool.
    disks:
      select:
        - { host: <str>, path_regex: <str> }
    # 2) Use all available disks of all hosts for this pool.
    #disks: all
...  # end of the document (optional)""")
        sys.exit()


def main(argv=None):
    opts = parse_opts(argv)
    try:
        input_str = sys.stdin.read()
        validate_schema(input_str, os.path.join(opts.dhall_dir, 'types',
                                                'ClusterDesc.dhall'))
        cluster_desc = yaml.safe_load(input_str)
    except KeyboardInterrupt:
        sys.exit(1)

    enrich_cluster_desc(cluster_desc, opts.mock)
    validate_cluster_desc(cluster_desc)

    if opts.debug:
        pprint(cluster_desc)
        return

    cluster = build_cluster(cluster_desc)

    outs: List[Tuple[str, Callable[..., str], List[Any]]] = [
        ('consul-agents.json', generate_consul_agents, cluster),
        ('consul-kv.json', generate_consul_kv, cluster.m0conf, opts.dhall_dir),
        ('confd.dhall', generate_confd, cluster.m0conf, opts.dhall_dir)]
    for path, generate, *args in outs:
        with open(os.path.join(opts.output_dir, path), 'w') as f:
            f.write(generate(*args))


def die(msg: str, status: int = 1):
    assert msg
    assert status != 0
    print(msg, file=sys.stderr)
    sys.exit(status)


def all_unique(xs) -> bool:
    """Returns True iff all entries of the sequence are unique.
    """
    if hasattr(xs, '__iter__') and hasattr(xs, '__next__'):
        # `xs` is a generator.  We should not consume it twice.
        xs = list(xs)
    return len(xs) == len(set(xs))


def validate_schema(input_str: str, schema_path: str) -> None:
    assert os.path.isabs(schema_path)
    proc = subprocess.Popen(['yaml-to-dhall', schema_path],
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    err = proc.communicate(input=input_str.encode(), timeout=15)[1]
    if proc.returncode != 0:
        die('Invalid input\n' + err.decode(), proc.returncode)


def enrich_cluster_desc(desc: Dict[str, Any], mock_p: bool) -> None:
    for host in desc['hosts']:
        # The fact names used here correspond to version 2.4.1 of `facter`.
        # See https://puppet.com/docs/puppet/6.6/core_facts.html#legacy-facts
        host['facts'] = get_facts(host['name'], mock_p,
                                  'hostname', 'processorcount',
                                  'memorysize_mb', 'macaddress')
        host['facts']['ipaddress'] = socket.gethostbyname(host['name'])
        host['facts']['_memsize_MB'] = int(float(
            host['facts']['memorysize_mb']))

        for m0d in host['m0_servers']:
            m0d.setdefault('runs_confd', False)
            disks = m0d.setdefault('io_disks', {'path_glob': None})
            disks['items'] = get_disks(host['name'], mock_p,
                                       disks['path_glob'])


def validate_cluster_desc(desc: Dict[str, Any]) -> None:
    assert all_unique(host['name'] for host in desc['hosts'])

    hosts = [(h['name'], h['facts']['ipaddress']) for h in desc['hosts']]
    assert all_unique(ip for _name, ip in hosts), \
        'IP addresses are not unique:\n' + \
        '\n'.join('    ' + name + ' ' + ip for name, ip in hosts)

    total_nr_confds = total_nr_disks = 0

    for host in desc['hosts']:
        def err(msg: str) -> str:
            return '{}: {}'.format(host['name'], msg)

        nr_confds = sum(1 for m0d in host['m0_servers'] if m0d['runs_confd'])
        assert nr_confds < 2, err('Too many confd services')
        total_nr_confds += nr_confds

        for m0d in host['m0_servers']:
            assert m0d['runs_confd'] or m0d['io_disks']['path_glob'], \
                err("Either 'runs_confd' or 'io_disks' must be set")

        disks: List[Disk] = []
        for m0d in host['m0_servers']:
            disks.extend(m0d['io_disks']['items'])
        assert all_unique(disks), err('Same disk used by several IO services')
        total_nr_disks += len(disks)

        assert nr_confds + host['c0_clients'] + host['m0t1fs_clients'] > 0, \
            err('At least one Mero server or client is required')

    assert total_nr_confds > 0, 'At least one confd is required'
    assert total_nr_disks > 0, 'No disks found'

    assert desc['pools'], 'List of pools must not be empty'


def run_command(hostname: str, *args: str) -> str:
    assert hostname

    cmd: List[str] = ['ssh', hostname]
    cmd.extend(args)
    return subprocess.check_output(cmd, timeout=15).decode()


def get_facts(hostname: str, mock_p: bool, *args: str) -> Dict[str, Any]:
    if mock_p:
        return fabricate_facts(hostname, *args)

    cmd = ['facter', '--json']
    cmd.extend(args)
    return json.loads(run_command(hostname, *cmd))


def fabricate_facts(hostname: str, *args: str) -> Dict[str, Any]:
    rng = random.randrange
    fabricated = {
        'hostname': re.sub('[^@]*@', '', hostname),
        'processorcount': rng(1, 21),
        'memorysize_mb': '{:.2f}'.format(random.uniform(512, 16000)),
        'ipaddress': '.'.join(str(n) for n in [
            random.choice([10, 172, 192]), rng(256), rng(256), rng(256)]),
        'macaddress': ':'.join('{:02x}'.format(n) for n in [
            rng(256), rng(256), rng(256), rng(256), rng(256), rng(256)]),
    }
    return dict((k, fabricated[k]) for k in args)


Disk = NamedTuple('Disk', [('path', str), ('size', int), ('blksize', int)])
Disk.size.__doc__ = 'Total size, in bytes'
Disk.blksize.__doc__ = 'Block size for file system I/O'


# XXX see build_disk_info() in mero's `utils/m0genfacts`
def get_disks(hostname: str, mock_p: bool, path_glob: str) -> List[Disk]:
    if mock_p:
        return fabricate_disks(hostname, path_glob)

    paths: List[str] = glob(path_glob) if path_glob else []
    if not paths:
        return []

    cmd = ['sudo', 'python3', '-c', f"""\"\
import io
import os

# os.path.getsize() and os.stat().st_size don't work well with loop devices,
# they always return 0.
def blockdev_size(path):
    with open(path, 'rb') as f:
        return f.seek(0, io.SEEK_END)

print([dict(path=path,
            size=blockdev_size(path),
            blksize=os.stat(path).st_blksize)
       for path in {paths!r}])
\""""]
    return [Disk(**kwargs) for kwargs in
            ast.literal_eval(run_command(hostname, *cmd))]


def fabricate_disks(hostname: str, path_glob: str) -> List[Disk]:
    if not path_glob:
        return []
    # XXX use `path_glob`
    return [Disk(path=f'/mock/disk{i}', size=0, blksize=4096)
            for i in range(10)]


ObjT = Enum('ObjT', 'root fdmi_flt_grp fdmi_filter'
            ' node process service sdev'  # software subtree
            ' site rack enclosure controller drive'  # hardware subtree
            ' pool pver pver_f objv'  # pool subtree
            ' profile')
ObjT.__doc__ = 'Mero conf object type'


def objT_to_dhall(t: ObjT) -> str:
    return 'types.ObjT.' + ''.join(s.capitalize() for s in t.name.split('_'))


Oid = NamedTuple('Oid', [('type', ObjT), ('fidk', int)])
Oid.__doc__ = 'Mero conf object identifier'
Oid.fidk.__doc__ = '.f_key part of the corresponding m0_fid'


def _infinite_counter(start: int = 0) -> Iterator[int]:
    k = start
    while True:
        yield k
        k += 1


fidk_gen = _infinite_counter()  # fid key generator


def new_oid(objt: ObjT) -> Oid:
    return Oid(objt, next(fidk_gen))


def oid_to_dhall(oid: Oid) -> str:
    return f'utils.zoid {objT_to_dhall(oid.type)} {oid.fidk}'


def oids_to_dhall(oids: List[Oid]) -> str:
    if not oids:
        return '[] : List types.Oid'
    return '[ {} ]'.format(', '.join(oid_to_dhall(x) for x in oids))


class Endpoint:
    _tmids: Dict[Tuple[str, int], int] = {}

    def __init__(self, ipaddr: str, portal: int, tmid: int = None):
        assert ipaddr
        self.ipaddr = ipaddr
        assert portal > 0
        self.portal = portal
        if tmid is None:
            self.tmid = Endpoint._tmids.setdefault((ipaddr, portal), 1)
            Endpoint._tmids[(ipaddr, portal)] += 1
        else:
            assert tmid > 0
            self.tmid = tmid

    def __repr__(self):
        args = ', '.join([f'ipaddr={self.ipaddr!r}',
                          f'portal={self.portal}'
                          f'tmid={self.tmid}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self):
        return f'utils.tcpEndpoint "{self.ipaddr}" {self.portal} {self.tmid}'

    def __str__(self):
        return f'{self.ipaddr}@tcp:12345:{self.portal}:{self.tmid}'


class ToDhall(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def to_dhall(self, oid: Oid) -> str:
        pass


Downlink = NamedTuple('Downlink', [('name', str), ('children_t', ObjT)])
Downlink.__doc__ = 'parent -> children relation'


class ConfRoot(ToDhall):
    _objt = ObjT.root
    _downlinks = {Downlink('nodes', ObjT.node),
                  Downlink('sites', ObjT.site),
                  Downlink('pools', ObjT.pool),
                  Downlink('profiles', ObjT.profile)}  # XXX + fdmi_flt_grps

    def __init__(self, nodes: List[Oid], sites: List[Oid], pools: List[Oid],
                 profiles: List[Oid], mdpool: Oid = None,
                 imeta_pver: Oid = None):
        assert all(x.type is ObjT.node for x in nodes)
        assert all(x.type is ObjT.site for x in sites)
        assert all(x.type is ObjT.pool for x in pools)
        assert all(x.type is ObjT.profile for x in profiles)
        assert mdpool is None or mdpool.type is ObjT.pool
        assert imeta_pver is None or imeta_pver.type is ObjT.pver

        self.nodes = nodes
        self.sites = sites
        self.pools = pools
        self.profiles = profiles
        self.mdpool = mdpool
        self.imeta_pver = imeta_pver

    def __repr__(self):
        args = ', '.join([f'nodes={self.nodes}',
                          f'sites={self.sites}',
                          f'pools={self.pools}',
                          f'profiles={self.profiles}',
                          f'mdpool={self.mdpool}',
                          f'imeta_pver={self.imeta_pver}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.root
        assert self.mdpool is not None
        imeta_pver = 'None types.Oid' if self.imeta_pver is None \
            else f'Some ({oid_to_dhall(self.imeta_pver)})'
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'mdpool = {oid_to_dhall(self.mdpool)}',
                          f'imeta_pver = {imeta_pver}',
                          f'nodes = {oids_to_dhall(self.nodes)}',
                          f'sites = {oids_to_dhall(self.sites)}',
                          f'pools = {oids_to_dhall(self.pools)}',
                          f'profiles = {oids_to_dhall(self.profiles)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any]) -> Oid:
        root_id = new_oid(ObjT.root)
        m0conf[root_id] = cls(nodes=[], sites=[], pools=[], profiles=[])
        return root_id


class ConfNode(ToDhall):
    _objt = ObjT.node
    _downlinks = {Downlink('processes', ObjT.process)}

    def __init__(self, hostname: str, nr_cpu: int, memsize_MB: int,
                 processes: List[Oid]):
        self.hostname = hostname
        self.nr_cpu = nr_cpu
        self.memsize_MB = memsize_MB
        assert all(x.type is ObjT.process for x in processes)
        self.processes = processes

    def __repr__(self):
        args = ', '.join([f'nr_cpu={self.nr_cpu}',
                          f'memsize_MB={self.memsize_MB}',
                          f'processes={self.processes}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.node
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'nr_cpu = {self.nr_cpu}',
                          f'memsize_MB = {self.memsize_MB}',
                          f'processes = {oids_to_dhall(self.processes)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              host_facts: Dict[str, Any]) -> Oid:
        assert parent.type is ObjT.root
        node_id = new_oid(ObjT.node)
        m0conf[node_id] = cls(hostname=host_facts['hostname'],
                              nr_cpu=host_facts['processorcount'],
                              memsize_MB=host_facts['_memsize_MB'],
                              processes=[])
        m0conf[parent].nodes.append(node_id)
        return node_id


ProcT = Enum('ProcT', 'hax m0_server m0_client')
ProcT.__doc__ = 'Type of the process'


class ConfProcess(ToDhall):
    _objt = ObjT.process
    _downlinks = {Downlink('services', ObjT.service)}

    def __init__(self, nr_cpu: int, memsize_MB: int, endpoint: Endpoint,
                 services: List[Oid]):
        assert nr_cpu > 0
        self.nr_cpu = nr_cpu
        assert memsize_MB > 0
        self.memsize_MB = memsize_MB
        self.endpoint = endpoint
        assert all(x.type is ObjT.service for x in services)
        self.services = services

    def __repr__(self):
        args = ', '.join([f'nr_cpu={self.nr_cpu}',
                          f'memsize_MB={self.memsize_MB}',
                          f'endpoint={self.endpoint}',
                          f'services={self.services}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.process
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'nr_cpu = {self.nr_cpu}',
                          f'memsize_MB = {self.memsize_MB}',
                          f'endpoint = {self.endpoint.to_dhall()}',
                          f'services = {oids_to_dhall(self.services)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              host_facts: Dict[str, Any], proc_t: ProcT,
              proc_desc: Dict[str, Any] = None,
              ctrl: Oid = None) -> Oid:
        assert parent.type is ObjT.node
        assert ctrl is None or ctrl.type is ObjT.controller

        ep = Endpoint(ipaddr=host_facts['ipaddress'], portal=proc_t.value)
        proc_id = new_oid(ObjT.process)
        m0conf[proc_id] = cls(nr_cpu=host_facts['processorcount'],
                              memsize_MB=host_facts['_memsize_MB'],
                              endpoint=ep, services=[])
        m0conf[parent].processes.append(proc_id)

        for stype in service_types(proc_t, proc_desc):
            svc_id = ConfService.build(m0conf, proc_id, stype, ep)
            if stype is SvcT.M0_CST_IOS:  # XXX What about M0_CST_CAS?
                assert proc_desc is not None and ctrl is not None
                for disk in proc_desc['io_disks']['items']:
                    ConfDrive.build(m0conf, ctrl,
                                    ConfSdev.build(m0conf, svc_id, disk))
        return proc_id


# m0_conf_service_type
class SvcT(Enum):
    """Mero service type
    """
    M0_CST_MDS = 1
    M0_CST_IOS = auto()
    M0_CST_CONFD = auto()
    M0_CST_RMS = auto()
    M0_CST_STATS = auto()
    M0_CST_HA = auto()
    M0_CST_SSS = auto()
    M0_CST_SNS_REP = auto()
    M0_CST_SNS_REB = auto()
    M0_CST_ADDB2 = auto()
    M0_CST_CAS = auto()
    M0_CST_DIX_REP = auto()
    M0_CST_DIX_REB = auto()
    M0_CST_DS1 = auto()
    M0_CST_DS2 = auto()
    M0_CST_FIS = auto()
    M0_CST_FDMI = auto()
    M0_CST_BE = auto()
    M0_CST_M0T1FS = auto()
    M0_CST_CLOVIS = auto()
    M0_CST_ISCS = auto()

    def to_dhall(self) -> str:
        return f'types.{self}'


def service_types(proc_t: ProcT,
                  proc_desc: Dict[str, Any] = None) -> List[SvcT]:
    ts = []
    if proc_t is ProcT.hax:
        ts.append(SvcT.M0_CST_HA)
    ts.append(SvcT.M0_CST_RMS)
    if proc_t is ProcT.m0_server:
        assert proc_desc is not None
        if proc_desc.get('runs_confd'):
            ts.append(SvcT.M0_CST_CONFD)
        if proc_desc['io_disks']['items']:
            ts.extend([SvcT.M0_CST_IOS,
                       SvcT.M0_CST_SNS_REP,
                       SvcT.M0_CST_SNS_REB,
                       SvcT.M0_CST_ADDB2,
                       SvcT.M0_CST_CAS,
                       SvcT.M0_CST_ISCS])
    return ts


class ConfService(ToDhall):
    _objt = ObjT.service
    _downlinks = {Downlink('sdevs', ObjT.sdev)}

    def __init__(self, stype: SvcT, endpoint: Endpoint, sdevs: List[Oid]):
        self.type = stype
        self.endpoint = endpoint
        assert all(x.type is ObjT.sdev for x in sdevs)
        self.sdevs = sdevs

    def __repr__(self):
        args = ', '.join([f'stype={self.type}',
                          f'endpoint={self.endpoint}',
                          f'sdevs={self.sdevs}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.service
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'type = {self.type.to_dhall()}',
                          f'endpoint = {self.endpoint.to_dhall()}',
                          f'sdevs = {oids_to_dhall(self.sdevs)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              stype: SvcT, endpoint: Endpoint) -> Oid:
        assert parent.type is ObjT.process
        svc_id = new_oid(ObjT.service)
        m0conf[svc_id] = cls(stype, endpoint, sdevs=[])
        m0conf[parent].services.append(svc_id)
        return svc_id


class ConfSdev(ToDhall):
    _dev_idx = _infinite_counter()
    _objt = ObjT.sdev
    _downlinks: Set[Downlink] = set()

    def __init__(self, dev_idx: int, filename: str, size: int, blksize: int):
        assert dev_idx >= 0
        assert filename
        assert size >= 0
        assert blksize >= 0

        self.dev_idx = dev_idx
        self.filename = filename
        self.size = size
        self.blksize = blksize

    def __repr__(self):
        args = ', '.join([f'dev_idx={self.dev_idx}',
                          f'filename={self.filename}',
                          f'size={self.size}',
                          f'blksize={self.blksize}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.sdev
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'dev_idx = {self.dev_idx}',
                          f'filename = "{self.filename}"',
                          f'size = {self.size}',
                          f'blksize = {self.blksize}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              disk_desc: Disk) -> Oid:
        assert parent.type is ObjT.service
        sdev_id = new_oid(ObjT.sdev)
        m0conf[sdev_id] = cls(dev_idx=next(cls._dev_idx),
                              filename=disk_desc.path,
                              size=disk_desc.size,
                              blksize=disk_desc.blksize)
        m0conf[parent].sdevs.append(sdev_id)
        return sdev_id


class ConfSite(ToDhall):
    _objt = ObjT.site
    _downlinks = {Downlink('racks', ObjT.rack)}

    def __init__(self, racks: List[Oid], pvers: List[Oid]):
        assert all(x.type is ObjT.rack for x in racks)
        self.racks = racks
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        args = ', '.join([f'racks={self.racks}',
                          f'pvers={self.pvers}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.site
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'racks = {oids_to_dhall(self.racks)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        site_id = new_oid(ObjT.site)
        m0conf[site_id] = cls(racks=[], pvers=[])
        assert not m0conf[parent].sites
        m0conf[parent].sites = [site_id]  # NB: a single site
        return site_id


class ConfRack(ToDhall):
    _objt = ObjT.rack
    _downlinks = {Downlink('encls', ObjT.enclosure)}

    def __init__(self, encls: List[Oid], pvers: List[Oid]):
        assert all(x.type is ObjT.enclosure for x in encls)
        self.encls = encls
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        args = ', '.join([f'encls={self.encls}',
                          f'pvers={self.pvers}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.rack
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'encls = {oids_to_dhall(self.encls)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.site
        rack_id = new_oid(ObjT.rack)
        m0conf[rack_id] = cls(encls=[], pvers=[])
        m0conf[rack_id]._parent = parent
        assert not m0conf[parent].racks
        m0conf[parent].racks = [rack_id]  # NB: a single rack
        return rack_id


class ConfEnclosure(ToDhall):
    _objt = ObjT.enclosure
    _downlinks = {Downlink('ctrls', ObjT.controller)}

    def __init__(self, ctrls: List[Oid], pvers: List[Oid]):
        assert all(x.type is ObjT.controller for x in ctrls)
        self.ctrls = ctrls
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        args = ', '.join([f'ctrls={self.ctrls}',
                          f'pvers={self.pvers}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.enclosure
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'ctrls = {oids_to_dhall(self.ctrls)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.rack
        encl_id = new_oid(ObjT.enclosure)
        m0conf[encl_id] = cls(ctrls=[], pvers=[])
        m0conf[encl_id]._parent = parent
        m0conf[parent].encls.append(encl_id)
        return encl_id


class ConfController(ToDhall):
    _objt = ObjT.controller
    _downlinks = {Downlink('drives', ObjT.drive)}

    def __init__(self, node: Oid, drives: List[Oid], pvers: List[Oid]):
        assert node.type is ObjT.node
        self.node = node
        assert all(x.type is ObjT.drive for x in drives)
        self.drives = drives
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        args = ', '.join([f'node={self.node}',
                          f'drives={self.drives}',
                          f'pvers={self.pvers}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.controller
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'node = {oid_to_dhall(self.node)}',
                          f'drives = {oids_to_dhall(self.drives)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid, node: Oid) -> Oid:
        assert parent.type is ObjT.enclosure
        assert node.type is ObjT.node

        ctrl_id = new_oid(ObjT.controller)
        m0conf[ctrl_id] = cls(node, drives=[], pvers=[])
        m0conf[ctrl_id]._parent = parent
        m0conf[parent].ctrls.append(ctrl_id)
        return ctrl_id


class ConfDrive(ToDhall):
    _objt = ObjT.drive
    _downlinks: Set[Downlink] = set()

    def __init__(self, sdev: Oid, pvers: List[Oid]):
        assert sdev.type is ObjT.sdev
        self.sdev = sdev
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        args = ', '.join([f'sdev={self.sdev}',
                          f'pvers={self.pvers}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.drive
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'sdev = {oid_to_dhall(self.sdev)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid, sdev: Oid) -> Oid:
        assert parent.type is ObjT.controller
        assert sdev.type is ObjT.sdev

        drive_id = new_oid(ObjT.drive)
        m0conf[drive_id] = cls(sdev, pvers=[])
        m0conf[drive_id]._parent = parent
        m0conf[parent].drives.append(drive_id)
        return drive_id


def pool_drives(m0conf: Dict[Oid, Any],
                pattern: Union[str, List[Dict[str, str]]]) -> List[Oid]:
    # XXX-TODO: support 'select' pattern; see cfgen/dhall/types/PoolDisks.dhall
    assert pattern == 'all'
    return [oid for oid in m0conf if oid.type is ObjT.drive]


class ConfPool(ToDhall):
    _objt = ObjT.pool
    _downlinks = {Downlink('pvers', ObjT.pver)}

    def __init__(self, pvers: List[Oid]):
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        return f'{self.__class__.__name__}(pvers={self.pvers})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.pool
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        pool_id = new_oid(ObjT.pool)
        m0conf[pool_id] = cls(pvers=[])
        m0conf[parent].pools.append(pool_id)
        return pool_id


Failures = NamedTuple('Failures', [('site', int),
                                   ('rack', int),
                                   ('enclosure', int),
                                   ('controller', int),
                                   ('drive', int)])
Failures.__doc__ = """\
Failure tolerance vector.

For a given pool version, the failure tolerance vector reflects how
many devices in each level can be expected to fail whilst still
allowing the remaining disks in that pool version to be read.

For disks, then, note that this will equal the parameter K, where
(N,K,P) is the triple of data units, parity units, pool width for
the pool version.

For controllers, this should indicate the maximum number such that
no failure of that number of controllers can take out more than K
units.  We can put an upper bound on this by considering
floor((nr_encls)/(N+K)), though distributional issues may result
in a lower value.
"""
pver_levels = Failures._fields


# m0_pdclust_attr
PDClustAttrs0 = NamedTuple('PDClustAttrs0',
                           # XXX What about `unit_size` and `seed`?
                           [('data_units', int), ('parity_units', int)])
PDClustAttrs0.__doc__ = 'Mero parity de-clustering layout attributes'


def tolerated_failures(m0conf: Dict[Oid, Any], pd_attrs: PDClustAttrs0,
                       drives: List[Oid]) -> Failures:
    assert pd_attrs.data_units > 0
    assert pd_attrs.parity_units >= 0
    assert drives and all(x.type is ObjT.drive for x in drives)
    assert all_unique(drives)

    n, k = pd_attrs

    nr_ctrls = 0
    for ctrl_id, ctrl in m0conf.items():
        if ctrl_id.type is not ObjT.controller:
            continue
        if not set(m0conf[ctrl_id].drives).isdisjoint(set(drives)):
            nr_ctrls += 1
    assert nr_ctrls > 0

    q, r = divmod(n + 2*k, nr_ctrls)
    # There are `r` controllers with `q+1` units and
    # `(nr_ctrls - r)` controllers with `q` units.
    #
    # In the worst scenario the most populated controllers
    # will go down first.
    #
    # `kc` is the number of parity group units that will be
    # unavailable when those `r` controllers go down.
    kc = r * (q + 1)
    if kc > k:
        # We won't be able to recover data if `kc` units are lost.
        # Recalculate the tolerable number of controller failures
        # by distributing the tolerable number of unit failures
        # (`k`) among the "most populous" controllers (`q+1` units
        # in each).
        ctrl_failures = k // (q + 1)
    elif kc < k:
        # `kc` units (`r` controllers) are lost, but we can
        # tolerate losing `k - kc` more units.
        # `(k - kc) // q` is the number of additional controller
        # failures that we can tolerate.
        ctrl_failures = r + (k - kc) // q
    else:
        # kc == k.  We can lose precisely `r` controllers;
        # no more, no less.
        ctrl_failures = r
    return Failures(site=0, rack=0, enclosure=0, controller=ctrl_failures,
                    drive=k)


class ConfPver(ToDhall):
    _objt = ObjT.pver
    _downlinks = {Downlink('sitevs', ObjT.objv)}

    def __init__(self, data_units: int, parity_units: int, pool_width: int,
                 tolerance: List[int], sitevs: List[Oid]):
        assert data_units > 0
        assert parity_units >= 0
        assert pool_width > 0
        assert len(tolerance) == len(pver_levels)
        assert all(n >= 0 for n in tolerance)
        assert all(x.type is ObjT.objv for x in sitevs)

        self.data_units = data_units
        self.parity_units = parity_units
        self.pool_width = pool_width
        self.tolerance = tolerance
        self.sitevs = sitevs

    def __repr__(self):
        args = ', '.join([f'data_units={self.data_units}',
                          f'parity_units={self.parity_units}',
                          f'pool_width={self.pool_width}',
                          f'tolerance={self.tolerance}',
                          f'sitevs={self.sitevs}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.pver
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'data_units = {self.data_units}',
                          f'parity_units = {self.parity_units}',
                          f'pool_width = {self.pool_width}',
                          f'tolerance = {self.tolerance}',
                          f'sitevs = {oids_to_dhall(self.sitevs)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              pd_attrs: PDClustAttrs0, drives: List[Oid],
              tolerance: Failures = None) -> Oid:
        assert parent.type is ObjT.pool
        assert drives and all(x.type is ObjT.drive for x in drives)
        assert all_unique(drives)

        pver_id = new_oid(ObjT.pver)  # "base" pool version
        m0conf[pver_id] = cls(
            data_units=pd_attrs.data_units,
            parity_units=pd_attrs.parity_units,
            pool_width=len(drives),
            tolerance=list(tolerated_failures(m0conf, pd_attrs, drives)
                           if tolerance is None else tolerance),
            sitevs=[])
        m0conf[parent].pvers.append(pver_id)
        build_pver_subtree(m0conf, pver_id, drives)
        # XXX-TODO: add formulaic pool versions; see addPVerFormulaic in Halon
        return pver_id


def build_pver_subtree(m0conf: Dict[Oid, Any], pver: Oid,
                       drives: List[Oid]) -> None:
    assert pver.type is ObjT.pver
    assert drives and all(x.type is ObjT.drive for x in drives)

    # Maps real object to the corresponding virtual object.
    virtual: Dict[Oid, Oid] = {}

    for drive in drives:
        assert drive not in virtual
        assert pver not in m0conf[drive].pvers
        m0conf[drive].pvers.append(pver)
        virtual[drive] = ConfObjv.build(m0conf, real=drive)

        devs = [drive]
        parent_types = [getattr(ObjT, x) for x in pver_levels[:-1]]
        while parent_types:
            devs.insert(0, m0conf[devs[0]]._parent)
            dev = devs[0]
            assert dev.type is parent_types.pop()
            parent_ready = dev in virtual
            if not parent_ready:
                assert pver not in m0conf[dev].pvers
                m0conf[dev].pvers.append(pver)
                virtual[dev] = ConfObjv.build(m0conf, real=dev)
            m0conf[virtual[dev]].children.append(virtual[devs[1]])
            if parent_ready:
                break

        if not parent_types:
            m0conf[pver].sitevs.append(virtual[devs[0]])


class ConfObjv(ToDhall):
    _objt = ObjT.objv
    _downlinks = {Downlink('children', ObjT.objv)}

    def __init__(self, real: Oid, children: List[Oid]):
        assert real.type in [getattr(ObjT, x) for x in pver_levels]
        self.real = real
        assert all(x.type is ObjT.objv for x in children)
        self.children = children

    def __repr__(self):
        args = ', '.join([f'real={self.real}',
                          f'children={self.children}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.objv
        args = ', '.join([f'id={oid_to_dhall(oid)}',
                          f'real={oid_to_dhall(self.real)}',
                          f'children={oids_to_dhall(self.children)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], real: Oid) -> Oid:
        assert real in m0conf
        objv_id = new_oid(ObjT.objv)
        m0conf[objv_id] = cls(real, [])
        return objv_id


class ConfProfile(ToDhall):
    _objt = ObjT.profile
    _downlinks = {Downlink('pools', ObjT.pool)}

    def __init__(self, pools: List[Oid]):
        assert all(x.type is ObjT.pool for x in pools)
        self.pools = pools

    def __repr__(self):
        return f'{self.__class__.__name__}(pools={self.pools})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.profile
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'pools = {oids_to_dhall(self.pools)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        prof_id = new_oid(ObjT.profile)
        m0conf[prof_id] = cls(pools=[])
        assert not m0conf[parent].profiles
        m0conf[parent].profiles = [prof_id]  # XXX-TODO: multiple profiles
        return prof_id


ConsulAgent = NamedTuple('ConsulAgent', [('hostname', str), ('ipaddr', str)])

Cluster = NamedTuple('Cluster', [('consul_servers', List[ConsulAgent]),
                                 ('consul_clients', List[ConsulAgent]),
                                 ('m0conf', Dict[Oid, Any])])


def generate_consul_agents(cluster: Cluster) -> str:
    assert cluster.consul_servers
    return json.dumps(
        {'servers': [x._asdict() for x in cluster.consul_servers],
         'clients': [x._asdict() for x in cluster.consul_clients]},
        indent=2) + '\n'


def generate_consul_kv(m0conf: Dict[Oid, Any], dhall_dir: str) -> str:
    assert os.path.isabs(dhall_dir)

    global fidk_gen
    _fidk_gen = next(fidk_gen)
    # Give up ownership of `fidk_gen`, passing it to the Consul KV.
    del fidk_gen

    ConsulService = NamedTuple('ConsulService', [
        ('node_name', str), ('proc_id', Oid), ('svc_types', str), ('ep', str)])

    def services() -> Iterator[ConsulService]:
        for node_id, node in m0conf.items():
            if node_id.type is not ObjT.node:
                continue
            for proc_id in node.processes:
                assert proc_id.type is ObjT.process
                stypes = ' '.join(
                    m0conf[svc_id].type.name[len('M0_CST_'):].lower()
                    for svc_id in m0conf[proc_id].services)
                yield ConsulService(node_name=node.hostname,
                                    proc_id=proc_id,
                                    svc_types=stypes,
                                    ep=str(m0conf[proc_id].endpoint))

    return json.dumps([dict(key=k, value=v) for k, v in (
        ('leader', ''),
        ('epoch', 1),
        ('last_fidk', _fidk_gen),
        *[(f'node/{x.node_name}/service/{x.proc_id.fidk}/types',
           f'{x.svc_types}') for x in services()],
        *[(f'node/{x.node_name}/service/{x.proc_id.fidk}/ep', f'{x.ep}')
          for x in services()])],
                      indent=2) + '\n'


def generate_confd(m0conf: Dict[Oid, ToDhall], dhall_dir: str) -> str:
    assert os.path.isabs(dhall_dir)

    def objt(obj: ToDhall) -> str:
        objt = obj.__class__.__name__
        assert objt.startswith('Conf')
        return objt[len('Conf'):]

    objs = '\n  , '.join('types.Obj.{} {}'.format(objt(v), v.to_dhall(k))
                         for k, v in m0conf.items())
    return f"""\
let types = {dhall_dir}/types.dhall
let utils = {dhall_dir}/utils.dhall

let objs =
  [ {objs}
  ]

in {dhall_dir}/toConfGen.dhall objs
"""


def validate_m0conf(m0conf: Dict[Oid, Any]) -> None:
    children_by_parent_type: Dict[ObjT, Dict[Downlink, List[Oid]]] = \
        dict((parent_t, {}) for parent_t in ObjT)
    for oid, obj in m0conf.items():
        assert oid.type is obj._objt
        assert oid.type.name == obj.__class__.__name__[len('Conf'):].lower()
        for rel in obj._downlinks:
            children = getattr(obj, rel.name)
            assert all_unique(children)
            assert all(x.type is rel.children_t for x in children)
            children_by_parent_type[oid.type].setdefault(rel.name, []) \
                                             .extend(children)
    assert all(all_unique(children)
               for _parent_t, rel_children in children_by_parent_type.items()
               for _rel, children in rel_children.items())


def build_cluster(cluster_desc: Dict[str, Any]) -> Cluster:
    cluster = Cluster(consul_servers=[], consul_clients=[], m0conf={})
    conf = cluster.m0conf
    root_id = ConfRoot.build(conf)
    # XXX Move all the logic into ConfRoot.build?

    rack_id = ConfRack.build(conf, ConfSite.build(conf, root_id))

    for host in cluster_desc['hosts']:
        facts = host['facts']

        node_id = ConfNode.build(conf, root_id, facts)
        ctrl_id = ConfController.build(conf,
                                       ConfEnclosure.build(conf, rack_id),
                                       node_id) \
            if any(m0d['io_disks']['items'] for m0d in host['m0_servers']) \
            else None

        ConfProcess.build(conf, node_id, facts, ProcT.hax)

        confd_p = False
        for m0d in host['m0_servers']:
            ConfProcess.build(conf, node_id, facts, ProcT.m0_server, m0d,
                              ctrl_id)
            if m0d['runs_confd']:
                confd_p = True
        (cluster.consul_servers if confd_p else cluster.consul_clients).\
            append(ConsulAgent(hostname=facts['hostname'],
                               ipaddr=facts['ipaddress']))

        for _ in range(host['c0_clients'] + host['m0t1fs_clients']):
            ConfProcess.build(conf, node_id, facts, ProcT.m0_client)

    # XXX-TODO: support multiple profiles
    prof_id = ConfProfile.build(conf, root_id)

    for pool in cluster_desc['pools']:
        pool_id = ConfPool.build(conf, root_id)
        ConfPver.build(conf, pool_id,
                       PDClustAttrs0(data_units=pool['data_units'],
                                     parity_units=pool['parity_units']),
                       pool_drives(conf, pool['disks']))
        conf[prof_id].pools.append(pool_id)

    # Metadata pool.
    if True:
        pool_id = ConfPool.build(conf, root_id)
        pool0 = cluster_desc['pools'][0]  # XXX Why the first pool?
        ctrls = set(conf[d]._parent for d in pool_drives(conf, pool0['disks']))
        first_drives = [conf[c].drives[0] for c in ctrls if conf[c].drives]
        ConfPver.build(conf, pool_id,
                       PDClustAttrs0(data_units=len(first_drives),
                                     parity_units=0),
                       drives=first_drives,
                       tolerance=Failures(0, 0, 0, 1, 0))
        conf[root_id].mdpool = pool_id

    # DIX pool.
    cas = [(svc_id, ctrl_id)
           for ctrl_id in conf if ctrl_id.type is ObjT.controller
           for proc_id in conf[conf[ctrl_id].node].processes
           for svc_id in conf[proc_id].services
           if conf[svc_id].type is SvcT.M0_CST_CAS]
    if cas:
        drives = [ConfDrive.build(conf, ctrl_id,
                                  ConfSdev.build(conf, svc_id,
                                                 Disk(path='/dev/null',
                                                      size=1024,
                                                      blksize=1)))
                  for (svc_id, ctrl_id) in cas]
        imeta_pver = ConfPver.build(
            conf,
            ConfPool.build(conf, root_id),
            PDClustAttrs0(
                # For CAS service N must always be equal to 1
                # as CAS records are indivisible pieces of data:
                # the whole CAS record is always stored on one node.
                data_units=1,
                parity_units=0),
            drives=drives,
            tolerance=Failures(0, 0, 0, 1, 0))
        conf[root_id].imeta_pver = imeta_pver

    validate_m0conf(conf)
    assert cluster.consul_servers
    names = [x.hostname
             for x in cluster.consul_servers + cluster.consul_clients]
    assert all_unique(names)
    assert all(re.search('[",= @]', name) is None for name in names)
    assert all_unique(x.ipaddr
                      for x in cluster.consul_servers + cluster.consul_clients)
    return cluster


if __name__ == '__main__':
    main()
