#!/usr/bin/env python3

import abc
import argparse
import ast
from enum import Enum, auto
from glob import glob
import json
import os
import random
import re
import subprocess
import sys
from typing import Any, Callable, Dict, Iterator, List, NamedTuple, Set, \
    Tuple, Union
import yaml


__version__ = '0.1'
__author__ = 'Valery V. Vorotyntsev <valery.vorotyntsev@seagate.com>'


def die(msg: str, status: int = 1):
    assert status != 0
    print(msg, file=sys.stderr)
    sys.exit(status)


def parse_opts(argv):
    p = argparse.ArgumentParser(
        description='Generate configuration files required to start'
        ' Mero cluster.',
        usage='%(prog)s [-o <output-dir>] [--mock]',
        epilog='The program reads cluster description in YAML format from the'
        " standard input; '--help-schema' option shows the schema.")
    p.add_argument('--help-schema', nargs=0, help='show cluster description'
                   ' file schema', action=ShowSchema)
    default_dhall_dir = '/opt/cfgen/dhall'
    p.add_argument('-D', '--dhall', metavar='dir',
                   help='directory with auxiliary Dhall expressions'
                   f' (defaults to {default_dhall_dir!r})',
                   dest='dhall_dir', default=default_dhall_dir)
    p.add_argument('-o', metavar='output-dir',
                   help="output directory (defaults to '.')",
                   dest='output_dir', default='.')
    p.add_argument('--mock', help='Generate pseudo-random "facts". The hosts'
                   ' specified in the cluster description file will not be'
                   " visited and don't even have to exist.",
                   action='store_true')
    p.add_argument('-V', '--version', action='version',
                   version='%(prog)s ' + __version__)
    opts = p.parse_args(argv)

    # Sanity check.
    for opt, d, perm in [('--dhall', opts.dhall_dir, os.R_OK),
                         ('-o', opts.output_dir, os.W_OK)]:
        if not (d and os.path.isdir(d) and os.access(d, os.X_OK | perm)):
            what = 'read' if perm == os.R_OK else 'writ'
            die(f'{opt!r} argument must be a path to {what}able directory')

    opts.dhall_dir = os.path.abspath(opts.dhall_dir)
    return opts


class ShowSchema(argparse.Action):
    def __call__(self, *args):
        print("""\
# Cluster Description is a YAML file with the following schema:
---  # start of the document (optional)
hosts:
  - name: <str>  # [user@]hostname; e.g., localhost, samir@10.22.33.44
    disks:
    m0_servers:
      - runs_confd: <bool>  # optional, defaults to false
        #io_disks: null                 # no IO service
        io_disks: { path_glob: <str> }  # e.g. "/dev/loop[0-9]*"
    c0_clients: <int>        # max quantity of Clovis apps this host may have
    m0t1fs_clients: <int>    # max quantity of m0t1fs clients
pools:
  - name: <str>
    allowed_failures:  # optional section; no failures will be allowed
                       # if this section is missing or all of its elements
                       # are zeroes
      site: <int>
      rack: <int>
      encl: <int>
      ctrl: <int>
      disk: <int>
    data_units: <int>
    parity_units: <int>
    #
    # There are two ways of assigning disks to pool.
    #
    # 1) Choose which disks of which host to use for this pool.
    disks:
      select:
        - { host: <str>, path_regex: <str> }
    # 2) Use all available disks of all hosts for this pool.
    #disks: all
...  # end of the document (optional)""")
        sys.exit()


def main(argv=None):
    opts = parse_opts(argv)
    try:
        input_str = sys.stdin.read()
        validate_schema(input_str, os.path.join(opts.dhall_dir, 'types',
                                                'ClusterDesc.dhall'))
        cluster_desc = yaml.safe_load(input_str)
    except KeyboardInterrupt:
        sys.exit(1)

    for host in cluster_desc['hosts']:
        # The fact names used here correspond to version 2.4.1 of `facter`.
        # See https://puppet.com/docs/puppet/6.6/core_facts.html#legacy-facts
        host['facts'] = get_facts(host['name'], opts.mock,
                                  'hostname', 'processorcount',
                                  'memorysize_mb', 'ipaddress', 'macaddress')
        host['facts']['_memsize_MB'] = int(float(
            host['facts']['memorysize_mb']))

        for m0d in host['m0_servers']:
            disks = m0d.setdefault('io_disks', {})
            disks['items'] = get_disks(host['name'], opts.mock,
                                       disks['path_glob'])

    validate_cluster_desc(cluster_desc)
    # # XXX DELETEME <<<<<<<
    # from pprint import pprint
    # pprint(cluster_desc)
    # sys.exit(9)
    # # XXX >>>>>>>

    m0conf = build_m0conf(cluster_desc)

    outs: List[Tuple[str, Callable[..., str], List[Any]]] = [
        ('bootstrap-env', generate_bootstrap_env,
         *cluster_nodes(cluster_desc)),
        ('confd.dhall', generate_confd, m0conf, opts.dhall_dir),
        ('consul-kv.json', generate_consul_kv, m0conf, opts.dhall_dir),
    ]
    for path, generate, *args in outs:
        with open(os.path.join(opts.output_dir, path), 'w') as f:
            f.write(generate(*args))


def all_unique(xs) -> bool:
    """Returns True iff all entries of the sequence are unique.
    """
    if hasattr(xs, '__iter__') and hasattr(xs, '__next__'):
        # `xs` is a generator.  We should not consume it twice.
        xs = list(xs)
    return len(xs) == len(set(xs))


def validate_schema(input_str: str, schema_path: str) -> None:
    assert os.path.isabs(schema_path)
    proc = subprocess.Popen(['yaml-to-dhall', schema_path],
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    err = proc.communicate(input=input_str.encode(), timeout=15)[1]
    if proc.returncode != 0:
        die('Invalid input\n' + err.decode(), proc.returncode)


def validate_cluster_desc(desc: Dict[str, Any]) -> None:
    assert all_unique(host['name'] for host in desc['hosts'])

    hosts = [(h['name'], h['facts']['ipaddress']) for h in desc['hosts']]
    assert all_unique(ip for _name, ip in hosts), \
        'IP addresses are not unique:\n' + \
        '\n'.join('    ' + name + ' ' + ip for name, ip in hosts)

    total_nr_confds = total_nr_disks = 0

    for host in desc['hosts']:
        def err(msg: str) -> str:
            return '{}: {}'.format(host['name'], msg)

        nr_confds = sum(1 for m0d in host['m0_servers'] if m0d['runs_confd'])
        assert nr_confds < 2, err('Too many confd services')
        total_nr_confds += nr_confds

        for m0d in host['m0_servers']:
            assert m0d['runs_confd'] or m0d['io_disks']['path_glob'], \
                err("Either 'runs_confd' or 'io_disks' must be set")

        disks: List[Disk] = []
        for m0d in host['m0_servers']:
            disks.extend(m0d['io_disks']['items'])
        assert all_unique(disks), err('Same disk used by several IO services')
        total_nr_disks += len(disks)

        assert nr_confds + host['c0_clients'] + host['m0t1fs_clients'] > 0, \
            err('At least one Mero server or client is required')

    assert total_nr_confds > 0, 'At least one confd is required'
    assert total_nr_disks > 0, 'No disks found'


def run_command(hostname: str, *args: str) -> str:
    assert hostname

    cmd: List[str] = []
    if hostname not in ('localhost', '127.0.0.1'):
        cmd = ['ssh', hostname]
    cmd.extend(args)
    return subprocess.check_output(cmd, timeout=15).decode()


def get_facts(hostname: str, mock_p: bool, *args: str) -> Dict[str, Any]:
    if mock_p:
        return fabricate_facts(hostname, *args)

    cmd = ['facter', '--json']
    cmd.extend(args)
    return json.loads(run_command(hostname, *cmd))


def fabricate_facts(hostname: str, *args: str) -> Dict[str, Any]:
    rng = random.randrange
    fabricated = {
        'hostname': re.sub('[^@]*@', '', hostname),
        'processorcount': rng(1, 21),
        'memorysize_mb': '{:.2f}'.format(random.uniform(512, 16000)),
        'ipaddress': '.'.join(str(n) for n in [
            random.choice([10, 172, 192]), rng(256), rng(256), rng(256)]),
        'macaddress': ':'.join('{:02x}'.format(n) for n in [
            rng(256), rng(256), rng(256), rng(256), rng(256), rng(256)]),
    }
    return dict((k, fabricated[k]) for k in args)


Disk = NamedTuple('Disk', [('path', str), ('size', int)])
Disk.size.__doc__ = 'Total space in bytes'


# XXX see build_disk_info() in mero's `utils/m0genfacts`
def get_disks(hostname: str, mock_p: bool, path_glob: str) -> List[Disk]:
    if mock_p:
        return fabricate_disks(hostname, path_glob)

    paths: List[str] = glob(path_glob) if path_glob else []
    if not paths:
        return []

    cmd = ['sudo', 'python3', '-c', f"""\
import io

def blockdev_size(path):
    with open(path, 'rb') as f:
        return f.seek(0, io.SEEK_END)

print([dict(path=path, size=blockdev_size(path)) for path in {paths!r}])
"""]
    return [Disk(**kwargs) for kwargs in
            ast.literal_eval(run_command(hostname, *cmd))]


def fabricate_disks(hostname: str, path_glob: str) -> List[Disk]:
    # XXX use `path_glob`
    return [Disk(path=f'/mock/disk{i}', size=0) for i in range(10)]


def cluster_nodes(cluster_desc: Dict[str, Any]) -> Tuple[List[str], List[str]]:
    hosts = list((host['facts']['hostname'],
                  any(m0d['runs_confd'] for m0d in host['m0_servers']))
                 for host in cluster_desc['hosts'])
    servers = list(hostname for hostname, confd_p in hosts if confd_p)
    clients = list(hostname for hostname, confd_p in hosts if not confd_p)

    names = servers + clients
    assert all_unique(names)
    assert all(re.search('[",= @]', name) is None for name in names)

    return servers, clients


ObjT = Enum('ObjT', 'root fdmi_flt_grp fdmi_filter'
            ' node process service sdev'  # software subtree
            ' site rack enclosure controller drive'  # hardware subtree
            ' pool pver pver_f objv'  # pool subtree
            ' profile')
ObjT.__doc__ = 'Mero conf object type'


def objT_to_dhall(t: ObjT) -> str:
    return 'types.ObjT.' + ''.join(s.capitalize() for s in t.name.split('_'))


Oid = NamedTuple('Oid', [('type', ObjT), ('fidk', int)])
Oid.__doc__ = 'Mero conf object identifier'
Oid.fidk.__doc__ = '.f_key part of the corresponding m0_fid'


def _infinite_counter():
    k = 0
    while True:
        yield k
        k += 1


fid_keygen = _infinite_counter()  # fid key generator


def new_oid(objt: ObjT) -> Oid:
    return Oid(objt, next(fid_keygen))


def oid_to_dhall(oid: Oid) -> str:
    return f'utils.zoid {objT_to_dhall(oid.type)} {oid.fidk}'


def oids_to_dhall(oids: List[Oid]) -> str:
    if not oids:
        return '[] : List types.Oid'
    return '[ {} ]'.format(', '.join(oid_to_dhall(x) for x in oids))


class Endpoint:
    _tmids = {}  # type: Dict[str, int]

    def __init__(self, ipaddr: str, tmid: int = None):
        assert ipaddr
        self.ipaddr = ipaddr
        if tmid is None:
            self.tmid = Endpoint._tmids.setdefault(ipaddr, 1)
            Endpoint._tmids[ipaddr] += 1
        else:
            assert tmid > 0
            self.tmid = tmid

    def __repr__(self):
        args = ', '.join([f'ipaddr={self.ipaddr!r}', f'tmid={self.tmid}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self):
        return f'utils.tcpEndpoint "{self.ipaddr}" 1975 {self.tmid}'


class ToDhall(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def to_dhall(self, oid: Oid) -> str:
        pass


Downlink = NamedTuple('Downlink', [('name', str), ('children_t', ObjT)])
Downlink.__doc__ = 'parent -> children relation'


class ConfRoot(ToDhall):
    _objt = ObjT.root
    _downlinks = {Downlink('nodes', ObjT.node),
                  Downlink('sites', ObjT.site),
                  Downlink('pools', ObjT.pool),
                  Downlink('profiles', ObjT.profile)}  # XXX + fdmi_flt_grps

    def __init__(self, nodes: List[Oid], sites: List[Oid], pools: List[Oid],
                 profiles: List[Oid]):
        assert all(x.type is ObjT.node for x in nodes)
        self.nodes = nodes
        assert all(x.type is ObjT.site for x in sites)
        self.sites = sites
        assert all(x.type is ObjT.pool for x in pools)
        self.pools = pools
        assert all(x.type is ObjT.profile for x in profiles)
        self.profiles = profiles

    def __repr__(self):
        args = ', '.join([f'nodes={self.nodes}',
                          f'sites={self.sites}',
                          f'pools={self.pools}',
                          f'profiles={self.profiles}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.root
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          'mdpool = XXX.Oid',
                          'imeta_pver = Some XXX.Oid',
                          f'nodes = {oids_to_dhall(self.nodes)}',
                          f'sites = {oids_to_dhall(self.sites)}',
                          f'pools = {oids_to_dhall(self.pools)}',
                          f'profiles = {oids_to_dhall(self.profiles)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any]) -> Oid:
        root_id = new_oid(ObjT.root)
        m0conf[root_id] = cls(nodes=[], sites=[], pools=[], profiles=[])
        return root_id


class ConfNode(ToDhall):
    _objt = ObjT.node
    _downlinks = {Downlink('processes', ObjT.process)}

    def __init__(self, hostname: str, nr_cpu: int, memsize_MB: int,
                 processes: List[Oid]):
        self.hostname = hostname
        self.nr_cpu = nr_cpu
        self.memsize_MB = memsize_MB
        assert all(x.type is ObjT.process for x in processes)
        self.processes = processes

    def __repr__(self):
        args = ', '.join([f'nr_cpu={self.nr_cpu}',
                          f'memsize_MB={self.memsize_MB}',
                          f'processes={self.processes}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.node
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'nr_cpu = {self.nr_cpu}',
                          f'memsize_MB = {self.memsize_MB}',
                          f'processes = {oids_to_dhall(self.processes)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              host_facts: Dict[str, Any]) -> Oid:
        assert parent.type is ObjT.root
        node_id = new_oid(ObjT.node)
        m0conf[node_id] = cls(hostname=host_facts['hostname'],
                              nr_cpu=host_facts['processorcount'],
                              memsize_MB=host_facts['_memsize_MB'],
                              processes=[])
        m0conf[parent].nodes.append(node_id)
        return node_id


class ConfProcess(ToDhall):
    _objt = ObjT.process
    _downlinks = {Downlink('services', ObjT.service)}

    def __init__(self, nr_cpu: int, memsize_MB: int, endpoint: Endpoint,
                 services: List[Oid]):
        assert nr_cpu > 0
        self.nr_cpu = nr_cpu
        assert memsize_MB > 0
        self.memsize_MB = memsize_MB
        self.endpoint = endpoint
        assert all(x.type is ObjT.service for x in services)
        self.services = services

    def __repr__(self):
        args = ', '.join([f'nr_cpu={self.nr_cpu}',
                          f'memsize_MB={self.memsize_MB}',
                          f'endpoint={self.endpoint}',
                          f'services={self.services}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.process
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'nr_cpu = {self.nr_cpu}',
                          f'memsize_MB = {self.memsize_MB}',
                          f'endpoint = {self.endpoint.to_dhall()}',
                          f'services = {oids_to_dhall(self.services)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              host_facts: Dict[str, Any],
              process_desc: Dict[str, Any] = None,
              ctrl: Oid = None) -> Oid:
        assert parent.type is ObjT.node
        assert ctrl is None or ctrl.type is ObjT.controller

        ep = Endpoint(ipaddr=host_facts['ipaddress'])
        proc_id = new_oid(ObjT.process)
        m0conf[proc_id] = cls(nr_cpu=host_facts['processorcount'],
                              memsize_MB=host_facts['_memsize_MB'],
                              endpoint=ep, services=[])
        m0conf[parent].processes.append(proc_id)

        for stype in service_types(process_desc):
            svc_id = ConfService.build(m0conf, proc_id, stype, ep)
            if stype is SvcT.M0_CST_IOS:  # XXX What about M0_CST_CAS?
                assert process_desc is not None and ctrl is not None
                for disk in process_desc['io_disks']['items']:
                    ConfDrive.build(m0conf, ctrl,
                                    ConfSdev.build(m0conf, svc_id, disk))
        return proc_id


# m0_conf_service_type
class SvcT(Enum):
    """Mero service type
    """
    M0_CST_MDS = 1
    M0_CST_IOS = auto()
    M0_CST_CONFD = auto()
    M0_CST_RMS = auto()
    M0_CST_STATS = auto()
    M0_CST_HA = auto()
    M0_CST_SSS = auto()
    M0_CST_SNS_REP = auto()
    M0_CST_SNS_REB = auto()
    M0_CST_ADDB2 = auto()
    M0_CST_CAS = auto()
    M0_CST_DIX_REP = auto()
    M0_CST_DIX_REB = auto()
    M0_CST_DS1 = auto()
    M0_CST_DS2 = auto()
    M0_CST_FIS = auto()
    M0_CST_FDMI = auto()
    M0_CST_BE = auto()
    M0_CST_M0T1FS = auto()
    M0_CST_CLOVIS = auto()
    M0_CST_ISCS = auto()

    def to_dhall(self) -> str:
        return f'types.{self}'


def service_types(process_desc: Dict[str, Any] = None) -> List[SvcT]:
    # Every program that uses m0_halon_interface API (ha/halon/interface.h
    # in `mero` repository) must be represented by at least 3 conf objects
    # in the Mero conf cache: a process object and two service objects
    # (HA and RMS).
    #
    # See http://gitlab.mero.colo.seagate.com/mero/hare/issues/8
    ts = [SvcT.M0_CST_HA, SvcT.M0_CST_RMS]

    if process_desc is not None:
        if process_desc.get('runs_confd'):
            ts.append(SvcT.M0_CST_CONFD)

        if process_desc['io_disks']['items']:
            ts.extend([SvcT.M0_CST_IOS,
                       SvcT.M0_CST_SNS_REP,
                       SvcT.M0_CST_SNS_REB,
                       SvcT.M0_CST_ADDB2,
                       SvcT.M0_CST_CAS,
                       SvcT.M0_CST_ISCS])
    return ts


class ConfService(ToDhall):
    _objt = ObjT.service
    _downlinks = {Downlink('sdevs', ObjT.sdev)}

    def __init__(self, stype: SvcT, endpoint: Endpoint, sdevs: List[Oid]):
        self.type = stype
        self.endpoint = endpoint
        assert all(x.type is ObjT.sdev for x in sdevs)
        self.sdevs = sdevs

    def __repr__(self):
        args = ', '.join([f'stype={self.type}',
                          f'endpoint={self.endpoint}',
                          f'sdevs={self.sdevs}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.service
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'type = {self.type.to_dhall()}',
                          f'endpoint = {self.endpoint.to_dhall()}',
                          f'sdevs = {oids_to_dhall(self.sdevs)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              stype: SvcT, endpoint: Endpoint) -> Oid:
        assert parent.type is ObjT.process
        svc_id = new_oid(ObjT.service)
        m0conf[svc_id] = cls(stype, endpoint, sdevs=[])
        m0conf[parent].services.append(svc_id)
        return svc_id


class ConfSdev(ToDhall):
    _dev_idx = _infinite_counter()
    _objt = ObjT.sdev
    _downlinks: Set[Downlink] = set()

    def __init__(self, dev_idx: int, filename: str, size: int):
        self.dev_idx = dev_idx
        self.filename = filename
        self.size = size

    def __repr__(self):
        args = ', '.join([f'dev_idx={self.dev_idx}',
                          f'filename={self.filename}',
                          f'size={self.size}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.sdev
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'dev_idx = {self.dev_idx}',
                          f'block_size = 4096',  # XXX BLOCK_SIZE
                          f'size = {self.size}',
                          f'filename = "{self.filename}"'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              disk_desc: Disk) -> Oid:
        assert parent.type is ObjT.service
        sdev_id = new_oid(ObjT.sdev)
        m0conf[sdev_id] = cls(dev_idx=next(cls._dev_idx),
                              filename=disk_desc.path,
                              size=disk_desc.size)
        m0conf[parent].sdevs.append(sdev_id)
        return sdev_id


class ConfSite(ToDhall):
    _objt = ObjT.site
    _downlinks = {Downlink('racks', ObjT.rack)}

    def __init__(self, racks: List[Oid]):
        assert all(x.type is ObjT.rack for x in racks)
        self.racks = racks

    def __repr__(self):
        return f'{self.__class__.__name__}(racks={self.racks})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.site
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'racks = {oids_to_dhall(self.racks)}',
                          'pvers = XXX.Oids'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        site_id = new_oid(ObjT.site)
        m0conf[site_id] = cls([])
        assert not m0conf[parent].sites
        m0conf[parent].sites = [site_id]  # NB: a single site
        return site_id


class ConfRack(ToDhall):
    _objt = ObjT.rack
    _downlinks = {Downlink('encls', ObjT.enclosure)}

    def __init__(self, encls: List[Oid]):
        assert all(x.type is ObjT.enclosure for x in encls)
        self.encls = encls

    def __repr__(self):
        return f'{self.__class__.__name__}(encls={self.encls})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.rack
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'encls = {oids_to_dhall(self.encls)}',
                          'pvers = XXX.Oids'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.site
        rack_id = new_oid(ObjT.rack)
        m0conf[rack_id] = cls([])
        m0conf[rack_id]._parent = parent
        assert not m0conf[parent].racks
        m0conf[parent].racks = [rack_id]  # NB: a single rack
        return rack_id


class ConfEnclosure(ToDhall):
    _objt = ObjT.enclosure
    _downlinks = {Downlink('ctrls', ObjT.controller)}

    def __init__(self, ctrls: List[Oid]):
        assert all(x.type is ObjT.controller for x in ctrls)
        self.ctrls = ctrls

    def __repr__(self):
        return f'{self.__class__.__name__}(ctrls={self.ctrls})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.enclosure
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'ctrls = {oids_to_dhall(self.ctrls)}',
                          'pvers = XXX.Oids'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.rack
        encl_id = new_oid(ObjT.enclosure)
        m0conf[encl_id] = cls([])
        m0conf[encl_id]._parent = parent
        m0conf[parent].encls.append(encl_id)
        return encl_id


class ConfController(ToDhall):
    _objt = ObjT.controller
    _downlinks = {Downlink('drives', ObjT.drive)}

    def __init__(self, node: Oid, drives: List[Oid]):
        assert node.type is ObjT.node
        self.node = node
        assert all(x.type is ObjT.drive for x in drives)
        self.drives = drives

    def __repr__(self):
        args = ', '.join([f'node={self.node}', f'drives={self.drives}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.controller
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'node = {oid_to_dhall(self.node)}',
                          f'drives = {oids_to_dhall(self.drives)}',
                          'pvers = XXX.Oids'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid, node: Oid) -> Oid:
        assert parent.type is ObjT.enclosure
        assert node.type is ObjT.node

        ctrl_id = new_oid(ObjT.controller)
        m0conf[ctrl_id] = cls(node, drives=[])
        m0conf[ctrl_id]._parent = parent
        m0conf[parent].ctrls.append(ctrl_id)
        return ctrl_id


class ConfDrive(ToDhall):
    _objt = ObjT.drive
    _downlinks: Set[Downlink] = set()

    def __init__(self, sdev: Oid):
        assert sdev.type is ObjT.sdev
        self.sdev = sdev

    def __repr__(self):
        return f'{self.__class__.__name__}(sdev={self.sdev})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.drive
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'sdev = {oid_to_dhall(self.sdev)}',
                          'pvers = XXX.Oids'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid, sdev: Oid) -> Oid:
        assert parent.type is ObjT.controller
        assert sdev.type is ObjT.sdev

        drive_id = new_oid(ObjT.drive)
        m0conf[drive_id] = cls(sdev)
        m0conf[drive_id]._parent = parent
        m0conf[parent].drives.append(drive_id)
        return drive_id


class ConfProfile(ToDhall):
    _objt = ObjT.profile
    _downlinks = {Downlink('pools', ObjT.pool)}

    def __init__(self, pools: List[Oid]):
        assert all(x.type is ObjT.pool for x in pools)
        self.pools = pools

    def __repr__(self):
        return f'{self.__class__.__name__}(pools={self.pools})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.profile
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'pools = {oids_to_dhall(self.pools)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        prof_id = new_oid(ObjT.profile)
        m0conf[prof_id] = cls(pools=[])
        assert not m0conf[parent].profiles
        m0conf[parent].profiles = [prof_id]  # XXX-TODO: multiple profiles
        return prof_id


def pool_drives(m0conf: Dict[Oid, Any],
                pattern: Union[str, List[Dict[str, str]]]) -> List[Oid]:
    assert pattern == 'all'  # XXX-TODO: support "select"
    return [oid for oid in m0conf if oid.type is ObjT.drive]


class ConfPool(ToDhall):
    _objt = ObjT.pool
    _downlinks = {Downlink('pvers', ObjT.pver)}

    def __init__(self, pvers: List[Oid]):
        assert all(x.type is ObjT.pver for x in pvers)
        self.pvers = pvers

    def __repr__(self):
        return f'{self.__class__.__name__}(pvers={self.pvers})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.pool
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'pvers = {oids_to_dhall(self.pvers)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid) -> Oid:
        assert parent.type is ObjT.root
        pool_id = new_oid(ObjT.pool)
        m0conf[pool_id] = cls([])
        m0conf[parent].pools.append(pool_id)
        return pool_id


Failures = NamedTuple('Failures', [
    ('site', int), ('rack', int), ('encl', int), ('ctrl', int), ('disk', int)])
Failures.__doc__ = """\
Failure tolerance vector.

For a given pool version, the failure tolerance vector reflects how
many devices in each level can be expected to fail whilst still
allowing the remaining disks in that pool version to be read.

For disks, then, note that this will equal the parameter K, where
(N,K,P) is the triple of data units, parity units, pool width for
the pool version.

For controllers, this should indicate the maximum number such that
no failure of that number of controllers can take out more than K
units.  We can put an upper bound on this by considering
floor((nr_encls)/(N+K)), though distributional issues may result
in a lower value.
"""


M0_CONF_PVER_HEIGHT = len(Failures._fields)


# m0_pdclust_attr
PDClustAttrs0 = NamedTuple('PDClustAttrs0',
                           # XXX What about `unit_size` and `seed`?
                           [('data_units', int), ('parity_units', int)])
PDClustAttrs0.__doc__ = 'Mero parity de-clustering layout attributes'


def tolerated_failures(m0conf: Dict[Oid, Any], pd_attrs: PDClustAttrs0,
                       drives: Set[Oid]) -> Failures:
    assert pd_attrs.data_units > 0
    assert pd_attrs.parity_units >= 0
    assert drives and all(x.type is ObjT.drive for x in drives)

    n, k = pd_attrs

    nr_ctrls = 0
    for ctrl_id, ctrl in m0conf.items():
        if ctrl_id.type is not ObjT.controller:
            continue
        if not set(m0conf[ctrl_id].drives).isdisjoint(drives):
            nr_ctrls += 1
    assert nr_ctrls > 0

    q, r = divmod(n + 2*k, nr_ctrls)
    # There are `r` controllers with `q+1` units and
    # `(nr_ctrls - r)` controllers with `q` units.
    #
    # In the worst scenario the most populated controllers
    # will go down first.
    #
    # `kc` is the number of parity group units that will be
    # unavailable when those `r` controllers go down.
    kc = r * (q + 1)
    if kc > k:
        # We won't be able to recover data if `kc` units are lost.
        # Recalculate the tolerable number of controller failures
        # by distributing the tolerable number of unit failures
        # (`k`) among the "most populous" controllers (`q+1` units
        # in each).
        ctrl_failures = k // (q + 1)
    elif kc < k:
        # `kc` units (`r` controllers) are lost, but we can
        # tolerate losing `k - kc` more units.
        # `(k - kc) // q` is the number of additional controller
        # failures that we can tolerate.
        ctrl_failures = r + (k - kc) // q
    else:
        # kc == k.  We can lose precisely `r` controllers;
        # no more, no less.
        ctrl_failures = r
    return Failures(site=0, rack=0, encl=0, ctrl=ctrl_failures, disk=k)


class ConfPver(ToDhall):
    _objt = ObjT.pver
    _downlinks = {Downlink('sitevs', ObjT.objv)}

    def __init__(self, data_units: int, parity_units: int, pool_width: int,
                 tolerance: List[int], sitevs: List[Oid]):
        assert data_units > 0
        assert parity_units >= 0
        assert pool_width > 0
        assert len(tolerance) == M0_CONF_PVER_HEIGHT
        assert all(n >= 0 for n in tolerance)
        assert all(x.type is ObjT.objv for x in sitevs)

        self.data_units = data_units
        self.parity_units = parity_units
        self.pool_width = pool_width
        self.tolerance = tolerance
        self.sitevs = sitevs

    def __repr__(self):
        args = ', '.join([f'data_units={self.data_units}',
                          f'parity_units={self.parity_units}',
                          f'pool_width={self.pool_width}',
                          f'tolerance={self.tolerance}',
                          f'sitevs={self.sitevs}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.pver
        args = ', '.join([f'id = {oid_to_dhall(oid)}',
                          f'data_units = {self.data_units}',
                          f'parity_units = {self.parity_units}',
                          f'pool_width = {self.pool_width}',
                          f'tolerance = {self.tolerance}',
                          f'sitevs = {oids_to_dhall(self.sitevs)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], parent: Oid,
              pd_attrs: PDClustAttrs0, drives: List[Oid]) -> Oid:
        assert parent.type is ObjT.pool
        assert drives and all(x.type is ObjT.drive for x in drives)
        assert all_unique(drives)

        pver_id = new_oid(ObjT.pver)  # "base" pool version
        m0conf[pver_id] = cls(
            data_units=pd_attrs.data_units,
            parity_units=pd_attrs.parity_units,
            pool_width=len(drives),
            tolerance=list(tolerated_failures(m0conf, pd_attrs, set(drives))),
            sitevs=[])
        m0conf[parent].pvers.append(pver_id)
        build_pver_subtree(m0conf, pver_id, drives)
        # XXX-TODO: add formulaic pool versions; see addPVerFormulaic in Halon
        return pver_id


def build_pver_subtree(m0conf: Dict[Oid, Any], pver: Oid,
                       drives: List[Oid]) -> None:
    assert pver.type is ObjT.pver
    assert drives and all(x.type is ObjT.drive for x in drives)

    # Maps real object to the corresponding virtual object.
    virtual: Dict[Oid, Oid] = {}

    for drive in drives:
        assert drive not in virtual
        virtual[drive] = ConfObjv.build(m0conf, real=drive)

        ctrl = m0conf[drive]._parent
        assert ctrl.type is ObjT.controller
        parent_ready = ctrl in virtual
        if not parent_ready:
            virtual[ctrl] = ConfObjv.build(m0conf, real=ctrl)
        m0conf[virtual[ctrl]].children.append(virtual[drive])
        if parent_ready:
            continue

        encl = m0conf[ctrl]._parent
        assert encl.type is ObjT.enclosure
        parent_ready = encl in virtual
        if not parent_ready:
            virtual[encl] = ConfObjv.build(m0conf, real=encl)
        m0conf[virtual[encl]].children.append(virtual[ctrl])
        if parent_ready:
            continue

        rack = m0conf[encl]._parent
        assert rack.type is ObjT.rack
        parent_ready = rack in virtual
        if not parent_ready:
            virtual[rack] = ConfObjv.build(m0conf, real=rack)
        m0conf[virtual[rack]].children.append(virtual[encl])
        if parent_ready:
            continue

        site = m0conf[rack]._parent
        assert site.type is ObjT.site
        parent_ready = site in virtual
        if not parent_ready:
            virtual[site] = ConfObjv.build(m0conf, real=site)
        m0conf[virtual[site]].children.append(virtual[rack])
        if parent_ready:
            continue

        m0conf[pver].sitevs.append(virtual[site])


class ConfObjv(ToDhall):
    _objt = ObjT.objv
    _downlinks = {Downlink('children', ObjT.objv)}

    def __init__(self, real: Oid, children: List[Oid]):
        assert real.type in (ObjT.site, ObjT.rack, ObjT.enclosure,
                             ObjT.controller, ObjT.drive)
        self.real = real
        assert all(x.type is ObjT.objv for x in children)
        self.children = children

    def __repr__(self):
        args = ', '.join([f'real={self.real}', f'children={self.children}'])
        return f'{self.__class__.__name__}({args})'

    def to_dhall(self, oid: Oid) -> str:
        assert oid.type is ObjT.objv
        args = ', '.join([f'id={oid_to_dhall(oid)}',
                          f'real={oid_to_dhall(self.real)}',
                          f'children={oids_to_dhall(self.children)}'])
        return '{ %s }' % args

    @classmethod
    def build(cls, m0conf: Dict[Oid, Any], real: Oid) -> Oid:
        objv_id = new_oid(ObjT.objv)
        m0conf[objv_id] = cls(real, [])
        return objv_id


def generate_bootstrap_env(servers: List[str], clients: List[str]) -> str:
    return """\
consul_server_nodes={}
consul_client_nodes={}
""".format(','.join(servers), ','.join(clients))


def generate_confd(m0conf: Dict[Oid, ToDhall], dhall_dir: str) -> str:
    assert os.path.isabs(dhall_dir)

    def objt(obj: ToDhall) -> str:
        objt = obj.__class__.__name__
        assert objt.startswith('Conf')
        return objt[len('Conf'):]

    objs = '\n  , '.join('types.Obj.{} {}'.format(objt(v), v.to_dhall(k))
                         for k, v in m0conf.items())
    return f"""\
let types = {dhall_dir}/types.dhall
let utils = {dhall_dir}/utils.dhall
let toConfGen = {dhall_dir}/toConfGen.dhall

let XXX =
  {{ Natural = 0
  , Oid = utils.zoid types.ObjT.Root 999
  , Oids = [] : List types.Oid
  }}

let objs =
  [ {objs}
  ]

in toConfGen objs
"""


def generate_consul_kv(m0conf: Dict[Oid, Any], dhall_dir: str) -> str:
    assert os.path.isabs(dhall_dir)

    global fid_keygen
    _fid_keygen = next(fid_keygen)
    # Give up ownership of `fid_keygen`, passing it to the Consul KV.
    del fid_keygen

    ConsulService = NamedTuple('ConsulService', [
        ('node_name', str), ('proc_id', Oid), ('svc_type', str)])

    def services() -> Iterator[ConsulService]:
        for node_id, node in m0conf.items():
            if node_id.type is not ObjT.node:
                continue
            for proc_id in node.processes:
                assert proc_id.type is ObjT.process
                for svc_id in m0conf[proc_id].services:
                    assert svc_id.type is ObjT.service
                    svc = m0conf[svc_id]
                    if svc.type in (SvcT.M0_CST_CONFD, SvcT.M0_CST_IOS):
                        svc_type = svc.type.name[len('M0_CST_'):].lower()
                        yield ConsulService(node_name=node.hostname,
                                            proc_id=proc_id,
                                            svc_type=svc_type)

    return json.dumps([dict(key=k, value=v) for k, v in (
        ('leader', ''),
        ('epoch', 1),
        ('last_fidk', _fid_keygen),
        *[(f'node/{x.node_name}/service/{x.svc_type}/{x.proc_id.fidk}', '')
          for x in services()])],
                      indent=2) + "\n"


def validate_m0conf(m0conf: Dict[Oid, Any]) -> None:
    children_by_parent_type: Dict[ObjT, Dict[Downlink, List[Oid]]] = \
        dict((parent_t, {}) for parent_t in ObjT)
    for oid, obj in m0conf.items():
        assert oid.type is obj._objt
        assert oid.type.name == obj.__class__.__name__[len('Conf'):].lower()
        for rel in obj._downlinks:
            children = getattr(obj, rel.name)
            assert all_unique(children)
            assert all(x.type is rel.children_t for x in children)
            children_by_parent_type[oid.type].setdefault(rel.name, []) \
                                             .extend(children)
    assert all(all_unique(children)
               for _parent_t, rel_children in children_by_parent_type.items()
               for _rel, children in rel_children.items())


def build_m0conf(cluster_desc: Dict[str, Any]) -> Dict[Oid, ToDhall]:
    conf: Dict[Oid, Any] = {}
    root_id = ConfRoot.build(conf)
    # XXX Move all the logic into ConfRoot.build.

    # XXX-TODO: support multiple profiles
    prof_id = ConfProfile.build(conf, root_id)

    rack_id = ConfRack.build(conf, ConfSite.build(conf, root_id))

    for host in cluster_desc['hosts']:
        facts = host['facts']

        node_id = ConfNode.build(conf, root_id, facts)
        encl_id = ConfEnclosure.build(conf, rack_id)

        ctrl_id = ConfController.build(conf, encl_id, node_id) \
            if any(m0d['io_disks']['items'] for m0d in host['m0_servers']) \
            else None

        ConfProcess.build(conf, node_id, facts)  # hax

        for m0d in host['m0_servers']:
            ConfProcess.build(conf, node_id, facts, m0d, ctrl_id)

        for _ in range(host['c0_clients'] + host['m0t1fs_clients']):
            ConfProcess.build(conf, node_id, facts)

    for pool in cluster_desc['pools']:
        pool_id = ConfPool.build(conf, root_id)
        ConfPver.build(conf, pool_id,
                       PDClustAttrs0(data_units=pool['data_units'],
                                     parity_units=pool['parity_units']),
                       pool_drives(conf, pool['disks']))
        conf[prof_id].pools.append(pool_id)

    validate_m0conf(conf)
    return conf


if __name__ == '__main__':
    main()
